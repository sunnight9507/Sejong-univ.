{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 강의교재\n",
    "\n",
    "* 주교재 : 강의록 (jupyter notebook)\n",
    "\n",
    "* 부교재: An introduction to statistical learning [PDF링크](https://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)\n",
    "\n",
    "* 단단한 머신러닝 (조우쯔화 지음/김태헌 옮김, 제이펍 출판사)\n",
    "\n",
    "## 1.1 기계학습(Machine learning)이란?  \n",
    "  \n",
    "  \n",
    "* 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야다. - 아서 새뮤얼(Arthur Samuel, 1959): Machine learning이란 용어를 처음 사용\n",
    "\n",
    "  \n",
    "* `어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정할 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.` - 톰 미첼(Tom Mitchell, 1997)\n",
    "\n",
    "    > 즉, 컴퓨터를 활용해 데이터(경험)에서 하나의 모델을 만들어내는 알고리즘에 대해 연구하는 분야\n",
    "    > 이때, 데이터를 통해 모델을 만들어가는 과정을 **학습(learning)** 또는 **훈련(training)**이라고 함\n",
    "    \n",
    "    > 예를 들어, 스팸필터는 스팸메일과 일반메일의 샘플을 이용해 스팸메일을 구분해낼수 있는 기계학습 프로그램\n",
    "    > - 시스템이 학습하는데 사용되는 샘플 데이터를 **훈련세트**라 하고, 각 훈련 데이터를 **훈련 사례(training instance)** 또는 **샘플**이라고 함\n",
    "    > - 미첼의 정의에서 작업 T는 새로운 메일이 스팸인지 아닌지를 구분하는 것이고, 경험 E는 훈련데이터\n",
    "    > - 성능 측정 P는 직접 정의해야 하는데, 예를 들어 정확히 분류된 메일의 비율 **정확도(accuracy)**를 성능 측정 P로 사용할 수 있음.  \n",
    "    \n",
    "* 기계학습(Machine learning)과 통계적학습(Statistical learning)  \n",
    "\n",
    "    > - 기계학습은 인공지능연구의 한 분야, 통계적학습은 통계학의 한 분야\n",
    "    > - 구분하는 것이 크게 의미는 없으나, 기계학습은 large scale의 응용분야에 많이 사용되고 예측(prediction)과 그 결과의 정확성을 좀 더 강조, 통계적학습은 모델의 해석가능성,추론(inference)과 불확실성(uncertainty)에 대한 연구를 좀더 강조 \n",
    "    \n",
    "* 데이터 마이닝(data mining)  \n",
    "\n",
    "    > 기계학습을 이용하여 대용량의 데이터를 분석하여 겉으로 보이지 않던 패턴을 찾는 것\n",
    "    \n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기계학습의 기본 용어 및 목표 \n",
    "\n",
    "#### 잘 익은 수박을 감별하는 기계학습을 진행하는 경우를 예로 들어 기계학습의 기본 용어와 표기법을 살펴보자.  \n",
    "\n",
    "* 수박 데이터를 수집하고 각 수박에 대해 세 가지 속성 '색깔', '꼭지 모양', '두들릴 때 소리'에 대한 정보를 다음과 같이 차례로 표기한다고 하자:  \n",
    "\n",
    "    - > (청록, 말림, 혼탁함), (진녹색, 약간 말림, 둔탁함), (연녹색, 곧음, 맑음), ...   \n",
    "    \n",
    "> 이런 기록들의 집합을 하나의 **데이터 세트(data set)** 라 함   \n",
    "\n",
    "> 각 기록은 하나의 대상에 대한 묘사이고, 이를 **사례(instance)** 혹은 **샘플(sample)** 이라고 함  \n",
    "\n",
    "> '색깔', \"꼭지모양\" 등 대상의 성질을 반양하는 것을 **속성(attribute)** 혹은 **특성(feature)**, **예측 변수(predictor variable)**이라 함  \n",
    "\n",
    "> '색깔' 속성에 대해 청록색, 진녹색 등과 같이 속성이 취할 수 있는 값을 **속성값(attribute value)** 이라고 함  \n",
    "\n",
    "> 고려하는 속성 종류의 개수 $n$를 샘플의 **차원(dimension)**이라 하고 $n$을 차원으로 갖는 좌표공간 $\\mathbb R^n$을 생각할 때, 속성값을 숫자로 나타내고 차례로 배열하여 벡터로 표현한 것을 **특성벡터(feature vector)** 라 함. 또 가능한 특성벡터들의 집합을 **입력공간(input space)** 또는 **샘플공간(sample space)**라고 함 (참고: 속성공간)\n",
    "\n",
    "> 이 강의에서 특성벡터는 $\\mathbf x, \\mathbf y,\\cdots$와 같이 굵은 소문자로 나타내고, 실수값은 $x,y,\\cdots$와 같이 소문자, (확률)변수는 대문자 $X,Y,\\cdots$로 표시. 또, 행렬은 $\\mathbf X,\\mathbf Y,\\cdots$와 같이 굵은 대문자로 표시  \n",
    "\n",
    "> 이 표기법을 따르면 $n$차원 샘플공간 $\\mathcal X$의 한 특성벡터는 $\\mathbf x=(x_1,x_2,\\cdots,x_n)$과 같이 쓸 수 있고,  $m$개의 샘플을 가지 데이터 세트는 $D=\\{\\mathbf x_1,\\mathbf x_2,\\cdots,\\mathbf x_m\\}$과 같이 쓸 수 있음  \n",
    "\n",
    ">    - 이때, $\\mathbf x_1= (x_{11},x_{12},\\cdots,x_{1n})$으로 나타냄  \n",
    "\n",
    ">    - 보통 각각의 샘플에 대응되는 특성벡터는 $n\\times 1$ 열벡터로 나타내고, $m$개의 샘플을 한꺼번에 다룰 때는 $i$번째 특성벡터를 $1\\times n$ 행벡터로 취급하여 $m\\times n$ 행렬의 $i$번째 행이 되도록 나타냄.  \n",
    "\n",
    ">    - 따라서 엄밀하게는 $\\mathbf x=(x_1,x_2,\\cdots,x_n)^{\\rm T}$로 나타내고, 데이터 세트는 $X=\\begin{pmatrix} \\mathbf x_1^{\\rm T} \\\\ \\mathbf x_2^{\\rm T} \\\\ \\cdots \\\\ \\mathbf x_m^{\\rm T}\\end{pmatrix}=\\begin{pmatrix} x_{11} & x_{12} & \\cdots & x_{1n}\\\\ x_{21} & x_{22} & \\cdots & x_{2n}\\\\ \\vdots & \\vdots & \\ddots & \\vdots\\\\ x_{m1} & x_{m2} & \\cdots & x_{mn}\\end{pmatrix}$로 나타냄\n",
    "\n",
    "> 데이터를 통해 모델을 만들어가는 과정을 **학습(learning)** 또는 **훈련(training)**이라 하고, 훈련과정에 사용되는 데이터를 **훈련 데이터**, 각 샘플을 **훈련 샘플**, 훈련 샘플들의 집합을 **훈련 세트**라고 함  \n",
    "\n",
    "> 학습 모델은 데이터 속에 잠재된 어떤 규칙에 대응하여 세운 **가설(hypothesis)**     \n",
    "    - 즉, 학습의 목표는 데이터를 통해 가설(학습 모델)을 세우고 잠재되어 있는 규칙을 찾거나 가까이 가는 것\n",
    "\n",
    "> 수박이 잘 익었는지를 판단할 수 있는 모델을 만드는 경우, 샘플 데이터만으로는 부족하고 훈련 샘플에 대한 결과 정보가 있어야 하는데 '잘 익은 수박' 처럼 결과를 나타내는 정보를 **레이블(label)**이라고 하고, 보통 영문자 $y$를 이용하여 나타냄(값인 경우 $y$, 벡터인 경우 $\\mathbf y$)  \n",
    ">\n",
    ">    - 잘 익은 수박에 대한 레이블을 숫자 $1$, 잘 익지 않은 수박에 대한 레이블을 숫자 $0$과 같이 나타낼 수 있음  \n",
    "    \n",
    "> 가능한 레이블들의 집합을 **레이블 공간** 또는 **출력 공간** 이라 하고 $\\mathcal Y$로 나타냄  \n",
    "\n",
    "> 일반적으로 $(\\mathbf x_i,y_i)$와 같은 형식으로 $i$ 번째 샘플을 표현함 ($\\mathbf x_i\\in \\mathcal X$, $y_i \\in \\mathcal Y$)\n",
    "\n",
    "> 학습한 모델을 활용하여 수박이 잘 익었는지를 판단하는 것을 **예측(prediction)**이라 하는데, '잘 익은 수박', '덜 익은 수박'과 같이 예측하려는 값이 이산적(discrete)인 학습 문제를 **분류(classification)** 문제라 하고, 예측하려는 값이 수박의 당도와 같이 연속적인 값이 되는 문제를 **회귀(regression)** 문제라 함  \n",
    "    - 두 가지 종류로 분류하는 분류 문제의 경우 각 클래스를 **양성클래스(positive class)**와 **음성클래스(negative class)**로 나타내기도 함  \n",
    "    - 두 가지 이상의 분류가 필요할 때 다항 분류 문제라고 함  \n",
    "    \n",
    "> 일반적으로 예측이란 훈련 세트 $\\{(\\mathbf x_i,y_i)| 1\\le i \\le m\\}$에 대해 학습하여 입력공간 $\\mathcal X$로부터 출력공간 $\\mathcal Y$로 가는 함수(잠재된 규칙) $f:\\mathcal X\\to \\mathcal Y$을 추정치(estimator)를 찾는 것 : 찾은 예측을 $\\hat f$로 나타냄  \n",
    "\n",
    ">    - $\\hat Y = \\hat f(X_1, X_2, \\cdots, X_n)$  \n",
    "\n",
    ">    - $(X_1,\\cdots, X_n)=\\mathbf x$에 대한 예측값 $\\hat y = \\hat f(\\mathbf x)$  \n",
    "\n",
    ">    - 데이터에 잠재된 규칙 $f$일 것으로 추정되는 함수 전체의 집합을 **가설공간**이라 하는데, 이 가설공간 자체, 가설공간의 특정 부분집합,가설공간에서 선택한 특정 가설를 혼용해서 학습모델이라고 말하기도 함  \n",
    "\n",
    ">    - 특히, 가설공간의 제한된 부분집합(예를 들어, 3차 다항함수들의 집합)을 학습모델로 제한하여 생각할 때, 각 학습모델은 $f(X)=\\theta_0+\\theta_1 X+\\theta_2 X^2+\\theta_3 X^3$과 같은 형태를 갖게 되는데, 특정모델을 결정하기 위해 필요한 $\\theta_i\\, (1\\le \\theta_i\\le 3)$을 **모델 파라미터(model parameter)**라고 말함\n",
    "    \n",
    "> $f$에 대한 예측(prediction)과 추론(inference)의 차이  \n",
    "    - 예측 : $\\hat f$를 일종의 블랙박스로 취급  \n",
    "    - 추론 : $\\hat f$를 이해하는데 중점\n",
    "\n",
    "#### 수박의 데이터 내에 잠재되어 있는 어떤 패턴에 대응하여 **군집화(클러스터링 clustering)**을 하는 기계학습도 가능  \n",
    "\n",
    "> 학습 과정에 레이블 데이터 $y_i$가 주어지지 않더라도 내재된 어떤 패턴에 따라 수박을 몇 개의 집단으로 나누는 기계학습  \n",
    "\n",
    "> 나누어진 각 집단을 **군집(클러스터 cluster)**라고 함 (예를 들어, 어떤 학습모델에 의해 나누어진 두 수박 집단 중 한 군집은 노지에서 수확한 수박이 대부분이고, 다른 군집은 비닐하우스에 생산된 수박이 대부분)\n",
    "\n",
    "#### 일반적으로 훈련 데이터가 레이블 테이터를 포함하고 있는지에 따라  \n",
    "\n",
    "#### **지도학습(supervised learning)**과 **비지도학습(unsupervised learning)**으로 나눌 수 있음   \n",
    "\n",
    "> 분류와 회귀는 지도학습의 예이고, 군집화는 비지도학습의 예 \n",
    "\n",
    "#### 주의해야 할 점:   \n",
    "\n",
    "**기계학습의 목표는 학습된 모델이 훈련 세트에서만 좋은 성능을 내는 것이 아니라**   \n",
    "\n",
    "**학습과정에서 보지 못한 데이터에 대해서도 좋은 성능을 내도록 하는 것**\n",
    "\n",
    "> 학습된 모델이 새로운 데이터에 적용되고 좋은 성능을 내는 것을 **일반화(generalization)** 능력이라고 함  \n",
    "\n",
    "> 일반화 능력을 확인하기 위해 사용되는 훈련 데이터 이외의 데이터를 **테스트 데이터(test data)**라고 함  \n",
    "\n",
    "> 샘플 공간의 모든 샘플이 미지의 동일한 분포 $\\mathcal D$를 따르고 서로 독립적이라고 가정 (훈련 샘플의 수가 많아질수록 분포 $\\mathcal D$에 대해 더 많이 알 수 있음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기계학습의 귀납적 편향\n",
    "\n",
    "#### 기계학습은 훈련 데이터를 이용하여 가능한 모든 가설 중에서 한 가설(모델)을 선택하는 것  \n",
    "\n",
    "#### 훈련 데이터로부터 일반화 능력을 가진 가설을 구성하는 것이므로 귀납적 학습   \n",
    "\n",
    "#### 유한개의 훈련 데이터를 이용하여 가설을 선택할 때는 반드시 어떤 **편향(bias)**를 가지고 있어야 정확하다고 여겨질 수 있는 모델을 생성하는 것이 가능\n",
    "\n",
    "> 예를 들어, 좌표평면에서 네 개의 훈련 샘플 $(x_i,y_i)\\, (1\\le i \\le 10)$이 주어질 때, $\\mathcal X = \\mathcal Y = \\mathbb R$에 대해 가설 $f:\\mathcal X \\to \\mathcal Y$을 선택하는 경우, 네 점을 모두 지나는 함수는 무수히 많음  \n",
    "\n",
    "> 비슷한 샘플들은 비슷한 출력값을 가져야 한다고 여긴다면 비교적 평활한 곡선을 선호하는 편향을 가진다고 할 수 있음\n",
    "\n",
    "#### 편향에 대한 일반적인 원칙: 오컴의 면도날(Occam's razor)  \n",
    "\n",
    "> 만약 다수의 가설이 관측된 것과 일치한다면, 가장 간단한 것을 선택해야 한다는 원칙 \n",
    "\n",
    "#### 구체적인 문제를 떠나서 '어떤 학습 알고리즘이 가장 좋은가?'를 논의하는 것은 아무런 의미가 없음 : No free lunch  \n",
    "\n",
    "> 'No free lunch theorem': 모든 잠재적인 문제를 고려한다면 모든 학습 알고리즘이 동등함을 보일 수 있음  \n",
    "\n",
    "> 즉, 어떤 가정도 하지 않으면 한 모델을 다른 모델보다 선호할 근거가 없다는 의미로, 어떤 모델이 최선인지 아는 유일한 방법은 모든 모델을 평가해보는 것  \n",
    "\n",
    "> 주어진 문제에 대해 모든 모델을 평가하는 것은 불가능하므로 데이터에 관해 타당한 가정을 하고 적절한 모델 몇 가지를 평가하여 최종 선택  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기계학습 시스템의 종류  \n",
    "\n",
    "#### * 학습하는 동안 레이블의 유무나 정보량에 따른 분류 :  \n",
    "\n",
    "**지도 학습**: 훈련 데이터에 레이블이 포함  \n",
    "> * 스팸인지 아닌지를 판단하는 문제와 같은 **분류**   \n",
    "> * (주행거리, 연식, 브랜드 등)을 이용해 중고차 가격을 구하는 문제와 같은 **회귀**\n",
    "> * 분류, 회귀와 관련된 학습 알고리즘 \n",
    "    - k-최근접 이웃(k-nearest neighbors), 선형 회귀(linear regression), 로지스틱 회귀(logistic regression),  \n",
    "    서포트 벡터 머신(SVM:support vector machine), 결정 트리(decision tree)와 랜덤 포레스트(random forest), 신경망(neural networks)\n",
    "\n",
    "**비지도 학습**: 훈련 데이터에 레이블이 없음  \n",
    "> * 군집화: 예) 주어진 기사에 나타나는 단어 특성을 이용하여 비슷한 주제별로 기사를 나누는 것 등  \n",
    "> * 군집화와 관련된 학습 알고리즘  \n",
    "    - k-평균(k-means), DBSCAN, 이상치 탐지(outlier detection), 특이치 탐지(novelty detection), 원-클래스 SVM  \n",
    "    \n",
    "> * 시각화(visualization)과 차원 축소(dimensionality reduction) : 너무 많은 정보를 잃지 않으면서 차원이 높은 데이터의 차원을 낮추는 것  \n",
    "> * 차원 축소와 관련된 학습 알고리즘 \n",
    "    - 주성분 분석(PCA: principal component analysis), 커널(kernel) PCA, 지역적 선형 임베딩(LLE: locally linear embedding), t-SNE(t-distrubuted stochastic neighbor embedding)\n",
    "    \n",
    "**준지도 학습**: 데이터 중 일부만 레이블이 있는 경우  \n",
    "\n",
    "**강화 학습**:  \n",
    "> * 에이전트(agent)라 부르는 시스템이 환경(environment)을 관찰해서 행동(action)을 실행하고 그 결과로 보상(reward)을 받음.  \n",
    "> * 시간이 지나면서 가장 큰 보상을 얻기 위한 **정책(policy)**라고 부르는 최상의 전략을 스스로 학습 (정책은 주어진 상황에서 에이전트가 어떤 행동을 선택해야 할지를 정의함)  \n",
    "> - 대표적인 예: 알파고, 자율주행  \n",
    "\n",
    "#### * 기계학습 시스템이 어떻게 일반화되는가에 따라 분류 :   \n",
    "\n",
    "**사례 기반 학습(instance based learning)**: 두 샘플 사이의 다양한 **유사도(similarity)**를 이용하여 일반화 (예측) \n",
    "> * k-최근접 이웃 : 새로운 샘플과 훈련 데이터 사이의 거리를 비교하는 방식으로 새로운 샘플에 일반화를 시도 \n",
    "\n",
    "**모델 기반 학습(model based learning)**: 샘플들의 모델을 만들어서 예측에 이용하는 방법으로 일반화 (추론)\n",
    "> * 예를 들어 하나의 특성에 대해 $\\hat Y = f(X)=\\theta_0 + \\theta_1 X$ 꼴의 선형 모델을 선택할 때,  \n",
    ">   - $\\theta_0, \\theta_1$과 같이 모델을 구성하는 파라미터를 **모델 파라미터(model parameter)**  \n",
    ">   - 모델이 얼마나 나쁜지를 측정하는 **비용 함수(cost function)** 또는 **손실 함수(loss function)**를 정의하고 훈련 데이터에 대해 손실함수의 값을 최소화시키는 방식으로 학습  \n",
    ">  - 예를 들어, 훈련 세트 $\\{( x_i, y_i)|1\\le i \\le m\\}$에 대한 손실 함수 값을 MAE:=$\\sum_{i=1}^m |y_i - \\hat y_i|$ 또는 MSE:=$\\sum_{i=1}^m |y_i - \\hat y_i|^2$로 정의  \n",
    "\n",
    "> * 즉, 훈련 세트에 모델을 맞추기 위해 모델 파라미터를 조정하는 방식 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기계학습의 주요 과제   \n",
    "\n",
    "#### 기계학습의 핵심이 학습 알고리즘(가설)을 선택해서 어떤 데이터에 훈련시키는 것이므로 문제가 될 수 있는 두 가지는 '나쁜 알고리즘'과 '나쁜 데이터'   \n",
    "\n",
    "> * 충분하지 않은 양의 훈련 데이터 \n",
    "\n",
    "> * 대표성이 없는 훈련 데이터: 샘플링 편향의 대표적인 예(랜던과 루즈벨트가 경쟁했던 미국 대통령 선거에서 천만 명을 대상으로 한 여론조사)  \n",
    ">   - 랜던이 57% 득표를 얻을 것이라고 높은 신뢰도로 예측했지만 루즈벨트가 62%로 당선  \n",
    ">   - 여론조사용 주소를 얻기 위해 사용한 명부가 공화당을 지지하는 부유계층에 편중  \n",
    ">   - 우편물 수신자의 25% 정도가 응답: 정치에 무관심한 사람, 해당 잡지사를 싫어하는 사람 등 중요 그룹을 제외시킴으로써 표본이 편향 \n",
    "\n",
    "> * 낮은 품질의 데이터: 일부 샘플이 이상치이거나 일부 샘플에 특성 몇 개가 빠진 경우 \n",
    "\n",
    "> * 관련 없는 특성: **특성 공학(feature engineerig)**을 통해 극복  \n",
    ">   - **특성 선택(feature selection)**: 가지고 있는 특성 중 유용한 특성을 선택  \n",
    ">   - **특성 추출(feature extraction)**: 특성을 결합하여 더 유용한 특성을 만듦  \n",
    "\n",
    "> * 훈련 데이터의 과대적합: 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어지는 것으로 다음과 같은 해결 방법을 이용   \n",
    ">   - 파라미터 수가 적은 모델을 선택하거나, 훈련 데이터에 있는 특성 수를 줄여서 해결 시도  \n",
    ">   - 훈련 데이터를 더 많이 모아서 해결 시도 \n",
    ">   - 오류 데이터 수정과 이상치 제거 등을 통해 훈련 데이터의 잡음을 줄여서 해결 시도 \n",
    ">   - 모델에 제약을 가해 단순화시켜서 해결 시도: 모델에 제약을 가하는 것을 **규제(regularization)**라고 함 \n",
    "\n",
    "**(참고)** 학습하는 동안 적용할 규제의 양을 조절하는 파라미터를 **하이퍼파라미터(hyperparameter)**라 하는데, 학습모델의 파라미터가 아니라 학습 알고리즘의 파라미터로써 학습 전에 미리 조정하고 학습하는 동안 상수로 남아 있음  \n",
    "\n",
    "> * 훈련 데이터의 과소적합: 모델이 너무 단순해서 데이터에 내재된 구조를 학습하지 못하는 것으로 다음과 같은 해결 방법을 이용  \n",
    ">   - 모델 파라미터가 더 많은 복잡한 모델을 선택하여 해결 시도  \n",
    ">   - 더 좋은 특성을 추가하여 해결 시도   \n",
    ">   - 모델에 제약을 완하시켜 해결 시도 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델의 평가와 선택    \n",
    "\n",
    "* 모델이 새로운 샘플에 얼마나 잘 일반화될 지를 아는 것은 새로운 샘플에 실제로 적용해 보는 것 \n",
    "\n",
    "* 훈련 데이터를 **훈련 세트**와 **테스트 세트**로 나눈 다음, 훈련 세트를 사용해 모델을 학습시키고 테스트 세트에 대한 오류 비율을 **일반화 오차**에 대한 추정치로 사용 \n",
    "\n",
    "* 선택한 모델에 대한 일반화 오차 예측: 테스트 세트를 이용하여 일반화 오차의 추정치 계산  \n",
    "\n",
    "* 동일한 문제에 대해 여러 모델 중 일반화가 가장 잘 될 것으로 기대되는 모델을 선택하는 방법:  \n",
    "\n",
    "> * **홀드아웃 검증(holdout validation)**: (테스트 세트와 분리한 훈련 세트가 충분히 클 때) 훈련세트를  다시 **훈련 세트**와 **검증 세트(validation set)**로 나누고 검증 세트를 이용하여 후보 모델들을 평가한 후 가장 좋은 하나를 선택  \n",
    "\n",
    "\n",
    "> * **교차 검증(cross validation)**: (테스트 세트와 분리한 훈련 세트가 충분히 크지 않을 때)  \n",
    ">   - 훈련세트에서 작은 검증 세트를 여러 개를 중복되지 않게 잡는다.  \n",
    ">   - 각 검증 세트마다 자신을 제외한 나머지 훈련 세트의 샘플을 이용하여 모든 모델을 각각 학습시킨다.  \n",
    ">   - 학습된 각 모델마다 검증 세트 별 평가를 평균하여 모델의 최종 평가를 구하고 이를 비교하여 최종 모델 선택  \n",
    ">   - 예를 들어 **k겹 교차 검증**은 전체 훈련 세트를 서로 겹치지 않는 k개의 부분집합으로 나누어 검증하는 것 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 강의 진행 방법 \n",
    "\n",
    "#### 본 강의는 기계학습 알고리즘의 이론적 근거를 이해하고 실제 데이터에 적용시키는 것을 목표로 함  \n",
    "\n",
    "#### 강의 자료는 jupyter note 형태로 제공 \n",
    "\n",
    "#### 몇 몇 알고리즘은 파이썬을 이용하여 싸이킷런(scikit-learn)에 구현되어 있는 형태로 직접 구현해보고, 이후에는 scikit-learn을 이용하여 실습  \n",
    "\n",
    "#### 파이썬(클래스 포함)과 넘파이(numpy), 쥬피터 노트북의 기본적인 내용을 알고 있는 것을 전제하고 간략하게 수업을 진행  (복습을 위한 강의 동영상 제공) \n",
    "\n",
    "#### pandas 라이브러리 기본 사용법부터 시작 : \n",
    "\n",
    "pandas는 파일 형태로 주어진 데이터를 읽어들여 학습에 필요한 특성 벡터 형태로 변환하고, 특성 벡터들 사이의 관계나 새로운 특성 벡터를 만드는데 유용한 파이썬 라이브러리 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
