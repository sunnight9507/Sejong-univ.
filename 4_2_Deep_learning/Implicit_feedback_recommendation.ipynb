{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고 : Collaborative Filtering for Implicit Feedback Datasets - Yifan Hu\n",
    "\n",
    "http://yifanhu.net/PUB/cf.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import csv\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영화 300개 자료 저장\n",
    "# User 수는 1000명\n",
    "data = {}\n",
    "movie_id = 0\n",
    "user_name = 0\n",
    "rating = 0\n",
    "user_list = []\n",
    "\n",
    "\n",
    "with open('combined_data_1.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if(line.find(\":\") != -1):\n",
    "            continue\n",
    "        line_split = line.split(',')\n",
    "        user_name = int(line_split[0])\n",
    "        if user_name in user_list:\n",
    "            continue\n",
    "        else:\n",
    "            user_list.append(user_name)\n",
    "        if len(user_list) > 1000:\n",
    "            break\n",
    "\n",
    "with open('combined_data_1.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if(line.find(\":\") != -1):\n",
    "            movie_id = int(line.replace(\":\",\"\")) - 1\n",
    "            if(movie_id >= 300): break\n",
    "            data[movie_id] = {}\n",
    "        else:\n",
    "            line_split = line.split(',')\n",
    "            user_name = int(line_split[0])\n",
    "            rating = int(line_split[1])\n",
    "            if user_name in user_list:\n",
    "                data[movie_id][user_name] = rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicit Feedback data X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 0., 0., ..., 0., 3., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 5., ..., 0., 0., 0.],\n",
       "       [0., 0., 3., ..., 0., 0., 0.],\n",
       "       [0., 0., 4., ..., 0., 5., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix = np.nan_to_num(np.array(pd.DataFrame(data)))\n",
    "\n",
    "Matrix"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선호도 행렬 P\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Raiting 값이 존재하면 1 / 존재하지 않으면 0으로 초기화\n",
    "P = np.copy(Matrix)\n",
    "P[P > 0] = 1\n",
    "print(P)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 신뢰도 행렬 C\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[121.   1.   1. ...   1. 121.   1.]\n",
      " [201.   1.   1. ...   1.   1.   1.]\n",
      " [161.   1.   1. ...   1.   1.   1.]\n",
      " ...\n",
      " [  1.   1. 201. ...   1.   1.   1.]\n",
      " [  1.   1. 121. ...   1.   1.   1.]\n",
      " [  1.   1. 161. ...   1. 201.   1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# alpha = 40 으로 초기화(논문에서 좋은 결과가 나온 값)\n",
    "C = 1 + 40 * Matrix\n",
    "print(C)\n",
    "print()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(C, P, xTy, lambda_, X, Y):\n",
    "    predict_error = np.square(P - xTy) # P - xTy => 실제값 - 예측값\n",
    "    return np.sum(predict_error), np.sum(C * predict_error) + lambda_ * (np.sum(np.square(X)) + np.sum(np.square(Y)))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize user factors\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize item factors\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X, Y, C, P, num_of_user, num_of_item, dimension, lambda_):\n",
    "    # user\n",
    "    yT = np.transpose(Y)\n",
    "    D = np.dot(lambda_, np.identity(dimension)) # lambda * identity_matirix\n",
    "    for u in range(num_of_user):\n",
    "        yT_Cu_y_D_inverse = np.linalg.inv(np.dot(np.dot(yT, np.diag(C[u])), Y) + D) # (yTCuY + D)의 역행렬\n",
    "        yT_Cu_pu = np.dot(np.dot(yT, np.diag(C[u])), P[u])\n",
    "        X[u] = np.dot(yT_Cu_y_D_inverse, yT_Cu_pu)\n",
    "    \n",
    "    # item\n",
    "    xT = np.transpose(X)\n",
    "    for i in range(num_of_item):\n",
    "        xT_Ci_x_D_inverse = np.linalg.inv(np.dot(np.dot(xT, np.diag(C[:, i])), X) + D) # (xT_Ci_x + D)의 역행렬\n",
    "        xT_Ci_pi = np.dot(np.dot(xT, np.diag(C[:, i])), P[:, i])\n",
    "        Y[i] = np.dot(xT_Ci_x_D_inverse, xT_Ci_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 파라미터별 최적값 확인\n",
    "- predict_error로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda : 10, dimension : 10 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "total loss: 79836.537725\n",
      "predict_error: 23910.747310\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 10 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "total loss: 87987.801473\n",
      "predict_error: 23561.789997\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 50 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 29796.383037\n",
      "predict_error: 7765.368555\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 50 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "total loss: 43524.086629\n",
      "predict_error: 8344.373881\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 90 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 25357.717392\n",
      "predict_error: 3338.720629\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 90 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 41952.954351\n",
      "predict_error: 4889.699461\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 130 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 23544.471101\n",
      "predict_error: 2134.328909\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 130 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 42437.221953\n",
      "predict_error: 4266.478283\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 170 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23596.815773\n",
      "predict_error: 1959.821126\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 170 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 43596.838072\n",
      "predict_error: 4054.628642\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 210 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23281.268019\n",
      "predict_error: 1942.943503\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 210 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 43196.400687\n",
      "predict_error: 4001.849047\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 250 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23094.108826\n",
      "predict_error: 1955.528158\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 250 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 42914.913303\n",
      "predict_error: 3993.238210\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 290 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23018.038115\n",
      "predict_error: 1973.107493\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 290 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 42427.453662\n",
      "predict_error: 4033.445499\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 330 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23000.573868\n",
      "predict_error: 1981.232615\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 330 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 42389.101814\n",
      "predict_error: 4012.209169\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 370 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23061.325248\n",
      "predict_error: 1992.308499\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 370 alpha : 10\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 42173.877894\n",
      "predict_error: 4032.948007\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 10 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "total loss: 90477.350885\n",
      "predict_error: 37839.104116\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 10 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "total loss: 129244.908326\n",
      "predict_error: 30630.867577\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 50 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 30208.121002\n",
      "predict_error: 9403.751336\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 50 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "---step 8---\n",
      "---step 9---\n",
      "total loss: 47704.234261\n",
      "predict_error: 9425.594752\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 90 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 24777.999383\n",
      "predict_error: 3976.945394\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 90 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "total loss: 44666.651401\n",
      "predict_error: 5008.928361\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 130 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23900.061989\n",
      "predict_error: 2610.358892\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 130 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 43296.640056\n",
      "predict_error: 4295.212011\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 170 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23814.800362\n",
      "predict_error: 2265.962882\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 170 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 43347.180269\n",
      "predict_error: 4165.748402\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 210 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 24184.813026\n",
      "predict_error: 2197.005970\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 210 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 42749.505426\n",
      "predict_error: 4226.671002\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 250 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 24518.374621\n",
      "predict_error: 2191.905882\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 250 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 43282.398908\n",
      "predict_error: 4205.862016\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 290 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 25106.358974\n",
      "predict_error: 2184.740219\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 290 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 43036.751528\n",
      "predict_error: 4259.825196\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 330 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 25588.757197\n",
      "predict_error: 2152.127269\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 330 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 43012.160822\n",
      "predict_error: 4279.336819\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 370 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 26018.730332\n",
      "predict_error: 2159.440003\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 370 alpha : 20\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 43054.151329\n",
      "predict_error: 4324.247949\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 10 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "total loss: 96966.987254\n",
      "predict_error: 47214.502363\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 10 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "total loss: 135256.175372\n",
      "predict_error: 40299.344481\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 50 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 30522.828044\n",
      "predict_error: 10502.037234\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 50 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "---step 8---\n",
      "total loss: 49327.509264\n",
      "predict_error: 10321.232176\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 90 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 25140.121904\n",
      "predict_error: 4460.699635\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 90 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 44954.209865\n",
      "predict_error: 5378.484448\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 130 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 24987.767841\n",
      "predict_error: 2864.785493\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 130 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 43320.652875\n",
      "predict_error: 4613.215299\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 170 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 25106.830071\n",
      "predict_error: 2410.983081\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 170 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 42933.725252\n",
      "predict_error: 4500.678001\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 210 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 26108.937830\n",
      "predict_error: 2314.358684\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 210 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 42846.806920\n",
      "predict_error: 4523.326493\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 250 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 26797.912786\n",
      "predict_error: 2311.380274\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 250 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---step 5---\n",
      "total loss: 43019.391230\n",
      "predict_error: 4538.160467\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 290 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 27498.060404\n",
      "predict_error: 2327.826380\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 290 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 43687.668680\n",
      "predict_error: 4514.142140\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 330 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 28235.242496\n",
      "predict_error: 2293.141578\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 330 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 44138.722558\n",
      "predict_error: 4503.942744\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 370 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 28754.473365\n",
      "predict_error: 2325.848804\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 370 alpha : 30\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 44880.938810\n",
      "predict_error: 4467.926305\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 10 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "total loss: 104352.803467\n",
      "predict_error: 53794.519997\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 10 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "total loss: 134472.094974\n",
      "predict_error: 48741.004425\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 50 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 31798.679569\n",
      "predict_error: 11379.503712\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 50 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "---step 7---\n",
      "total loss: 49553.944982\n",
      "predict_error: 11223.655067\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 90 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 26415.337061\n",
      "predict_error: 4840.158279\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 90 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 44250.780404\n",
      "predict_error: 5764.034987\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 130 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 26002.169989\n",
      "predict_error: 2811.454058\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 130 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 43340.722039\n",
      "predict_error: 4893.567608\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 170 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 26565.769175\n",
      "predict_error: 2509.032101\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 170 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 43499.584654\n",
      "predict_error: 4705.202946\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 210 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 27932.169043\n",
      "predict_error: 2414.005707\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 210 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 44041.041580\n",
      "predict_error: 4665.556018\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 250 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 28829.616693\n",
      "predict_error: 2413.523905\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 250 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 44770.782661\n",
      "predict_error: 4638.861582\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 290 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 29414.077905\n",
      "predict_error: 2455.974996\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 290 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "total loss: 46311.829960\n",
      "predict_error: 4561.171966\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 330 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 30123.111913\n",
      "predict_error: 2453.296689\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 330 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 46610.544786\n",
      "predict_error: 4494.146127\n",
      "\n",
      "\n",
      "lambda : 10, dimension : 370 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 30750.956218\n",
      "predict_error: 2490.734945\n",
      "\n",
      "\n",
      "lambda : 20, dimension : 370 alpha : 40\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "---step 5---\n",
      "---step 6---\n",
      "total loss: 47917.946570\n",
      "predict_error: 4424.057546\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 각 파라미터별 total_loss\n",
    "result = []\n",
    "\n",
    "# 정규화에 필요한 lambda\n",
    "lambda_ = [i for i in range(10,30,10)]\n",
    "\n",
    "# Latent Factor 행렬의 차원\n",
    "dimension = [i for i in range(10,410,40)]\n",
    "\n",
    "# Latent Factor 행렬의 차원\n",
    "alpha_ = [i for i in range(10,50,10)]\n",
    "\n",
    "# user, item 수 \n",
    "num_of_user, num_of_item = Matrix.shape[0], Matrix.shape[1]\n",
    "\n",
    "for a in alpha_:\n",
    "    for d in dimension:\n",
    "        for l in lambda_:\n",
    "            # Latent Factor Matrix 초기 랜덤값 생성\n",
    "            # X : 유저\n",
    "            # Y : 영화\n",
    "            np.random.seed(100)\n",
    "            X = np.random.rand(num_of_user, d) * 0.01\n",
    "            Y = np.random.rand(num_of_item, d) * 0.01\n",
    "\n",
    "            C = 1 + a * Matrix\n",
    "            temp_losses = 10000000\n",
    "            temp_predict_error = 10000000\n",
    "\n",
    "            print('dimension : %d, lambda : %d, alpha : %d' %(l,d,a))\n",
    "            print()\n",
    "            i = 0\n",
    "            while(True):\n",
    "                i += 1\n",
    "                print('---step %d---' % i)\n",
    "                if i!=0:    \n",
    "                    optimize(X, Y, C, P, num_of_user, num_of_item, d, l)\n",
    "                    predict = np.dot(X, np.transpose(Y))\n",
    "                    predict_error, total_loss = loss_function(C, P, predict,l,X,Y)\n",
    "\n",
    "                    if temp_predict_error < predict_error:\n",
    "                        break                \n",
    "                    if temp_losses - total_loss < 1000 or i == 10: # Overfitting 방지\n",
    "                        break\n",
    "\n",
    "                temp_predict_error = predict_error\n",
    "                temp_losses = total_loss\n",
    "\n",
    "            print(\"total loss: %f\" % total_loss)\n",
    "            print(\"predict_error: %f\" % predict_error)\n",
    "            print()\n",
    "            print()\n",
    "\n",
    "            result.append([d,l,a,predict_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>210</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1942.943503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>250</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1955.528158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>170</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1959.821126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>290</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1973.107493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>330</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1981.232615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>37839.104116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>40299.344481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>47214.502363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>48741.004425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>53794.519997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2             3\n",
       "10  210  10  10   1942.943503\n",
       "12  250  10  10   1955.528158\n",
       "8   170  10  10   1959.821126\n",
       "14  290  10  10   1973.107493\n",
       "16  330  10  10   1981.232615\n",
       "..  ...  ..  ..           ...\n",
       "20   10  10  20  37839.104116\n",
       "41   10  20  30  40299.344481\n",
       "40   10  10  30  47214.502363\n",
       "61   10  20  40  48741.004425\n",
       "60   10  10  40  53794.519997\n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict_error \n",
    "pd.DataFrame(result).sort_values(by = [3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가장 이상적인 초기값\n",
    "    - dimension = 210\n",
    "    - lambda_ = 10\n",
    "    - alpha = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda : 10, dimension : 210\n",
      "\n",
      "---step 1---\n",
      "---step 2---\n",
      "---step 3---\n",
      "---step 4---\n",
      "total loss: 23281.268019\n",
      "predict_error: 1942.943503\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lambda_ = 10\n",
    "l = 10\n",
    "# dimension = 210\n",
    "d = 210\n",
    "alpha = 10\n",
    "\n",
    "# user, item 수 \n",
    "num_of_user, num_of_item = Matrix.shape[0], Matrix.shape[1]\n",
    "\n",
    "# Latent Factor Matrix 초기 랜덤값 생성\n",
    "# X : 유저\n",
    "# Y : 영화\n",
    "np.random.seed(100)\n",
    "X = np.random.rand(num_of_user, d) * 0.01\n",
    "Y = np.random.rand(num_of_item, d) * 0.01\n",
    "\n",
    "C = 1 + alpha * Matrix\n",
    "temp_losses = 10000000\n",
    "temp_predict_error = 10000000\n",
    "\n",
    "print('lambda : %d, dimension : %d' %(l,d))\n",
    "print()\n",
    "i = 0\n",
    "while(True):\n",
    "    i += 1\n",
    "    print('---step %d---' % i)\n",
    "    if i!=0:    \n",
    "        optimize(X, Y, C, P, num_of_user, num_of_item, d, l)\n",
    "        predict = np.dot(X, np.transpose(Y))\n",
    "        predict_error, total_loss = loss_function(C, P, predict,l,X,Y)\n",
    "\n",
    "        if temp_predict_error < predict_error:\n",
    "            break                \n",
    "        if temp_losses - total_loss < 1000 or i == 10:\n",
    "            break\n",
    "\n",
    "    temp_predict_error = predict_error\n",
    "    temp_losses = total_loss\n",
    "\n",
    "print(\"total loss: %f\" % total_loss)\n",
    "print(\"predict_error: %f\" % predict_error)\n",
    "print()\n",
    "print()\n",
    "\n",
    "result_matrix = np.dot(X, np.transpose(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.990046</td>\n",
       "      <td>0.198061</td>\n",
       "      <td>0.212851</td>\n",
       "      <td>0.028474</td>\n",
       "      <td>0.039580</td>\n",
       "      <td>0.192591</td>\n",
       "      <td>0.029017</td>\n",
       "      <td>0.973627</td>\n",
       "      <td>0.105254</td>\n",
       "      <td>-0.103369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.978127</td>\n",
       "      <td>-0.071150</td>\n",
       "      <td>-0.103485</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>-0.007204</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>0.025168</td>\n",
       "      <td>-0.002813</td>\n",
       "      <td>0.010658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.983041</td>\n",
       "      <td>0.102815</td>\n",
       "      <td>-0.038222</td>\n",
       "      <td>-0.058152</td>\n",
       "      <td>0.920232</td>\n",
       "      <td>0.114736</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.052261</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.016193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.992375</td>\n",
       "      <td>0.086655</td>\n",
       "      <td>0.152055</td>\n",
       "      <td>-0.056535</td>\n",
       "      <td>0.753697</td>\n",
       "      <td>0.097807</td>\n",
       "      <td>-0.011138</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>-0.015046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.981479</td>\n",
       "      <td>0.197987</td>\n",
       "      <td>0.188059</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>-0.035248</td>\n",
       "      <td>0.901856</td>\n",
       "      <td>-0.044796</td>\n",
       "      <td>0.016373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.989451</td>\n",
       "      <td>0.118670</td>\n",
       "      <td>0.187099</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.037209</td>\n",
       "      <td>0.101098</td>\n",
       "      <td>0.016376</td>\n",
       "      <td>0.123127</td>\n",
       "      <td>-0.003510</td>\n",
       "      <td>-0.068534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.985814</td>\n",
       "      <td>-0.007074</td>\n",
       "      <td>-0.040777</td>\n",
       "      <td>0.018928</td>\n",
       "      <td>0.015590</td>\n",
       "      <td>-0.002111</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>0.068630</td>\n",
       "      <td>-0.003450</td>\n",
       "      <td>-0.002245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.995922</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>-0.071534</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>0.087657</td>\n",
       "      <td>-0.013616</td>\n",
       "      <td>0.040515</td>\n",
       "      <td>0.024319</td>\n",
       "      <td>-0.014468</td>\n",
       "      <td>-0.030751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.989243</td>\n",
       "      <td>0.113568</td>\n",
       "      <td>0.113001</td>\n",
       "      <td>-0.006745</td>\n",
       "      <td>0.064438</td>\n",
       "      <td>-0.015276</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.132048</td>\n",
       "      <td>0.003447</td>\n",
       "      <td>-0.011738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.971176</td>\n",
       "      <td>-0.070644</td>\n",
       "      <td>-0.102749</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>-0.007153</td>\n",
       "      <td>0.013392</td>\n",
       "      <td>0.024989</td>\n",
       "      <td>-0.002793</td>\n",
       "      <td>0.010582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.990046  0.198061  0.212851  0.028474  0.039580  0.192591  0.029017   \n",
       "1  0.978127 -0.071150 -0.103485  0.005360  0.002237 -0.007204  0.013487   \n",
       "2  0.983041  0.102815 -0.038222 -0.058152  0.920232  0.114736 -0.012939   \n",
       "3  0.992375  0.086655  0.152055 -0.056535  0.753697  0.097807 -0.011138   \n",
       "4  0.981479  0.197987  0.188059  0.018772  0.001706  0.049316 -0.035248   \n",
       "5  0.989451  0.118670  0.187099  0.001756  0.037209  0.101098  0.016376   \n",
       "6  0.985814 -0.007074 -0.040777  0.018928  0.015590 -0.002111  0.004160   \n",
       "7  0.995922 -0.000328 -0.071534  0.011828  0.087657 -0.013616  0.040515   \n",
       "8  0.989243  0.113568  0.113001 -0.006745  0.064438 -0.015276  0.003515   \n",
       "9  0.971176 -0.070644 -0.102749  0.005322  0.002221 -0.007153  0.013392   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.973627  0.105254 -0.103369  \n",
       "1  0.025168 -0.002813  0.010658  \n",
       "2  0.052261  0.019089  0.016193  \n",
       "3 -0.002097  0.000913 -0.015046  \n",
       "4  0.901856 -0.044796  0.016373  \n",
       "5  0.123127 -0.003510 -0.068534  \n",
       "6  0.068630 -0.003450 -0.002245  \n",
       "7  0.024319 -0.014468 -0.030751  \n",
       "8  0.132048  0.003447 -0.011738  \n",
       "9  0.024989 -0.002793  0.010582  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최종 예측값\n",
    "predict = pd.DataFrame(result_matrix)\n",
    "predict.iloc[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9\n",
       "0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0\n",
       "1  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2  4.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0\n",
       "3  4.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "4  3.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "5  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "6  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "7  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "8  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "9  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Matrix).iloc[:10,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 결과값과 실제 Rating값을 비교해보면 Raiting값이 있을 경우 예측값은 1에 가깝고 없는 경우 0에 가깝다.\n",
    "- Raiting이 없는 값중에 예측값이 1에 가까우면 추천\n",
    "\n",
    "#### 예시) user = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198061</td>\n",
       "      <td>0.212851</td>\n",
       "      <td>0.028474</td>\n",
       "      <td>0.039580</td>\n",
       "      <td>0.192591</td>\n",
       "      <td>0.029017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105254</td>\n",
       "      <td>-0.103369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036394</td>\n",
       "      <td>0.253148</td>\n",
       "      <td>-0.023703</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>0.217782</td>\n",
       "      <td>-0.033534</td>\n",
       "      <td>0.048648</td>\n",
       "      <td>0.032442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.071150</td>\n",
       "      <td>-0.103485</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>-0.007204</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>0.025168</td>\n",
       "      <td>-0.002813</td>\n",
       "      <td>0.010658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>-0.013040</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-0.033087</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>0.025807</td>\n",
       "      <td>-0.003876</td>\n",
       "      <td>0.018369</td>\n",
       "      <td>0.026196</td>\n",
       "      <td>-0.005332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102815</td>\n",
       "      <td>-0.038222</td>\n",
       "      <td>-0.058152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114736</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.052261</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.016193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084161</td>\n",
       "      <td>0.057057</td>\n",
       "      <td>-0.099870</td>\n",
       "      <td>-0.059629</td>\n",
       "      <td>0.074814</td>\n",
       "      <td>0.012655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015940</td>\n",
       "      <td>0.028457</td>\n",
       "      <td>-0.041020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086655</td>\n",
       "      <td>0.152055</td>\n",
       "      <td>-0.056535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097807</td>\n",
       "      <td>-0.011138</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>-0.015046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030711</td>\n",
       "      <td>0.074229</td>\n",
       "      <td>0.059497</td>\n",
       "      <td>0.034581</td>\n",
       "      <td>0.325895</td>\n",
       "      <td>0.052772</td>\n",
       "      <td>0.160295</td>\n",
       "      <td>0.054738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.024661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197987</td>\n",
       "      <td>0.188059</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>-0.035248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.044796</td>\n",
       "      <td>0.016373</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013568</td>\n",
       "      <td>0.050493</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.013551</td>\n",
       "      <td>0.119313</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.039184</td>\n",
       "      <td>0.023053</td>\n",
       "      <td>0.245213</td>\n",
       "      <td>-0.031987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>0.136358</td>\n",
       "      <td>0.114995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>-0.069068</td>\n",
       "      <td>0.105528</td>\n",
       "      <td>0.022008</td>\n",
       "      <td>0.083375</td>\n",
       "      <td>0.076550</td>\n",
       "      <td>0.142308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015526</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.089827</td>\n",
       "      <td>0.178674</td>\n",
       "      <td>0.154045</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.091487</td>\n",
       "      <td>0.039763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>0.050310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.029178</td>\n",
       "      <td>0.038497</td>\n",
       "      <td>-0.025289</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>0.062069</td>\n",
       "      <td>0.034392</td>\n",
       "      <td>0.102724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012304</td>\n",
       "      <td>0.062689</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.043852</td>\n",
       "      <td>-0.015912</td>\n",
       "      <td>0.034289</td>\n",
       "      <td>0.090060</td>\n",
       "      <td>0.012826</td>\n",
       "      <td>0.155788</td>\n",
       "      <td>0.016913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>-0.064336</td>\n",
       "      <td>0.026340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014294</td>\n",
       "      <td>-0.030449</td>\n",
       "      <td>0.138030</td>\n",
       "      <td>0.007172</td>\n",
       "      <td>0.033306</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.084504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012115</td>\n",
       "      <td>-0.066581</td>\n",
       "      <td>0.202405</td>\n",
       "      <td>0.215998</td>\n",
       "      <td>-0.012067</td>\n",
       "      <td>-0.009559</td>\n",
       "      <td>0.133812</td>\n",
       "      <td>-0.036132</td>\n",
       "      <td>0.123027</td>\n",
       "      <td>0.022776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>-0.047714</td>\n",
       "      <td>-0.094503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041351</td>\n",
       "      <td>-0.090336</td>\n",
       "      <td>-0.046905</td>\n",
       "      <td>0.016197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006875</td>\n",
       "      <td>0.063495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028000</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.105107</td>\n",
       "      <td>0.089016</td>\n",
       "      <td>0.024869</td>\n",
       "      <td>-0.064380</td>\n",
       "      <td>0.120131</td>\n",
       "      <td>0.062767</td>\n",
       "      <td>0.005340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.030709</td>\n",
       "      <td>0.044062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000606</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>0.103676</td>\n",
       "      <td>0.015153</td>\n",
       "      <td>0.076101</td>\n",
       "      <td>0.006611</td>\n",
       "      <td>-0.035207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039751</td>\n",
       "      <td>0.047354</td>\n",
       "      <td>-0.067307</td>\n",
       "      <td>-0.020323</td>\n",
       "      <td>0.174584</td>\n",
       "      <td>-0.025776</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>-0.014967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.000000  0.198061  0.212851  0.028474  0.039580  0.192591  0.029017   \n",
       "1     0.000000 -0.071150 -0.103485  0.005360  0.002237 -0.007204  0.013487   \n",
       "2     0.000000  0.102815 -0.038222 -0.058152  0.000000  0.114736 -0.012939   \n",
       "3     0.000000  0.086655  0.152055 -0.056535  0.000000  0.097807 -0.011138   \n",
       "4     0.000000  0.197987  0.188059  0.018772  0.001706  0.049316 -0.035248   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "996   0.136358  0.114995  0.000000  0.008873 -0.069068  0.105528  0.022008   \n",
       "997   0.010713  0.050310  0.000000 -0.029178  0.038497 -0.025289 -0.000510   \n",
       "998  -0.064336  0.026340  0.000000  0.014294 -0.030449  0.138030  0.007172   \n",
       "999  -0.047714 -0.094503  0.000000  0.041351 -0.090336 -0.046905  0.016197   \n",
       "1000  0.030709  0.044062  0.000000 -0.000606  0.007450  0.103676  0.015153   \n",
       "\n",
       "           7         8         9    ...       290       291       292  \\\n",
       "0     0.000000  0.105254 -0.103369  ... -0.036394  0.253148 -0.023703   \n",
       "1     0.025168 -0.002813  0.010658  ...  0.001345 -0.013040  0.010032   \n",
       "2     0.052261  0.019089  0.016193  ...  0.084161  0.057057 -0.099870   \n",
       "3    -0.002097  0.000913 -0.015046  ...  0.030711  0.074229  0.059497   \n",
       "4     0.000000 -0.044796  0.016373  ... -0.013568  0.050493  0.001181   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "996   0.083375  0.076550  0.142308  ... -0.015526  0.077160  0.089827   \n",
       "997   0.062069  0.034392  0.102724  ... -0.012304  0.062689  0.000502   \n",
       "998   0.033306  0.001112  0.084504  ... -0.012115 -0.066581  0.202405   \n",
       "999   0.000000 -0.006875  0.063495  ... -0.028000  0.002040 -0.127985   \n",
       "1000  0.076101  0.006611 -0.035207  ... -0.039751  0.047354 -0.067307   \n",
       "\n",
       "           293       294       295       296       297       298       299  \n",
       "0     0.009244  0.217782 -0.033534  0.048648  0.032442  0.000000  0.042164  \n",
       "1    -0.033087  0.003904  0.025807 -0.003876  0.018369  0.026196 -0.005332  \n",
       "2    -0.059629  0.074814  0.012655  0.000000  0.015940  0.028457 -0.041020  \n",
       "3     0.034581  0.325895  0.052772  0.160295  0.054738  0.000000 -0.024661  \n",
       "4     0.013551  0.119313  0.001635  0.039184  0.023053  0.245213 -0.031987  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "996   0.178674  0.154045  0.005356  0.091487  0.039763  0.000000  0.019580  \n",
       "997   0.043852 -0.015912  0.034289  0.090060  0.012826  0.155788  0.016913  \n",
       "998   0.215998 -0.012067 -0.009559  0.133812 -0.036132  0.123027  0.022776  \n",
       "999  -0.105107  0.089016  0.024869 -0.064380  0.120131  0.062767  0.005340  \n",
       "1000 -0.020323  0.174584 -0.025776  0.000540 -0.014967  0.000000 -0.000796  \n",
       "\n",
       "[1001 rows x 300 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rating이 없는 값 중 예측값 확인\n",
    "Test = np.copy(Matrix)\n",
    "Test[Test == 0] = -1\n",
    "Test[Test > 0] = 0\n",
    "Test[Test < 0] = 1\n",
    "(predict * Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 영화별 예측값 정렬후 원하는 수만큼 위에서부터 영화 추천\n",
    "\n",
    "- user = 0 인 경우에 영화 3개를 추천할 때 268,165,126인 영화를 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268    0.456564\n",
       "165    0.433882\n",
       "126    0.421913\n",
       "160    0.347012\n",
       "95     0.305039\n",
       "         ...   \n",
       "113   -0.102080\n",
       "9     -0.103369\n",
       "263   -0.107994\n",
       "191   -0.119782\n",
       "112   -0.128457\n",
       "Name: 0, Length: 300, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predict * Test).iloc[0,:].sort_values(ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
