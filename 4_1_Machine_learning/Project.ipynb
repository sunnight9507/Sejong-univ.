{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.decomposition import PCA # PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"project_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫번째 분석 방법\n",
    "\n",
    "### 1) 이상치 제거\n",
    "### 2) 정규화\n",
    "### 3) PCA\n",
    "### 4) 로지스틱을 이용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value - mean의 절대값이 5시그마 밖의 값이면 이상치라 가정하고 제거\n",
    "for i in data1.iloc[:,1:30]:\n",
    "    data1 = data1[~(abs(data1[i] - data1[i].mean()) > 5*data1[i].std())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y로 나누고 X값들을 정규화\n",
    "X = data1.iloc[:,1:30]\n",
    "Y = data1.iloc[:,30]\n",
    "for i in X:\n",
    "    X[i] = (X[i] - X[i].mean())/X[i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.623337, 14.352209, 20.633861, 26.349525, 31.617967, 36.534743,\n",
       "        41.3223  , 45.939378, 50.463384, 54.809141, 59.039765, 63.003636,\n",
       "        66.77815 , 70.394455, 73.951452, 77.480637, 80.995487, 84.416027,\n",
       "        87.800113, 90.622305, 92.593778, 94.37697 , 95.80591 , 97.172102,\n",
       "        98.294107, 99.189599, 99.956628, 99.997534, 99.999998]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA\n",
    "pca_num = PCA(n_components=29)\n",
    "X_PCA_T = pca_num.fit_transform(X)\n",
    "X_PCA = pca_num.fit(X)\n",
    "\n",
    "X_PCA_sum = np.cumsum(np.round(X_PCA.explained_variance_ratio_, decimals=8)*100) \n",
    "X_PCA_sum_varc = np.array(np.transpose(X_PCA_sum[:,np.newaxis])) \n",
    "\n",
    "X_PCA_sum_varc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과에서 17번까지의 특징을 이용하면 전체 데이터의 80%를 설명할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_y = np.c_[X_PCA_T,Y]\n",
    "# 데이터프레임으로 변경\n",
    "Data = pd.DataFrame(pc_y)\n",
    "\n",
    "X = Data.iloc[:,0:17]\n",
    "Y = Data.iloc[:,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunni\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     74681\n",
      "         1.0       0.00      0.00      0.00        23\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     74704\n",
      "   macro avg       0.50      0.50      0.50     74704\n",
      "weighted avg       1.00      1.00      1.00     74704\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunni\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.4,random_state=1)\n",
    "\n",
    "Log = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "Log_target_predict = Log.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, Log_target_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 봤을 때 어떤 데이터를 넣어도 Class = 0으로 예측을 한 것을 알 수 있다.\n",
    "\n",
    "결과적으로 Class가 1인 데이터를 하나도 분류하지 못했다.\n",
    "\n",
    "- 발견한 것 : 이상치 제거할 때 Class 값이 1인 데이터들이 대략 70%, Class가 0인 데이터는 50%가 사라진 것을 발견            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두번째 분석 방법\n",
    "\n",
    "### 1) 정규화\n",
    "### 2) PCA\n",
    "### 3) 로지스틱을 이용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y로 나누고 X값들을 정규화\n",
    "X = data2.iloc[:,1:30]\n",
    "Y = data2.iloc[:,30]a\n",
    "for i in X:\n",
    "    X[i] = (X[i] - X[i].mean())/X[i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.821957,  10.472614,  14.054332,  17.581883,  21.059338,\n",
       "         24.534958,  28.005411,  31.473655,  34.935393,  38.39431 ,\n",
       "         41.84903 ,  45.301213,  48.746796,  52.188403,  55.628551,\n",
       "         59.061438,  62.492848,  65.919956,  69.344699,  72.766799,\n",
       "         76.186152,  79.598404,  83.005469,  86.410194,  89.806455,\n",
       "         93.191683,  96.556926,  99.865013, 100.      ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA\n",
    "pca_num = PCA(n_components=29)\n",
    "X_PCA_T = pca_num.fit_transform(X)\n",
    "X_PCA = pca_num.fit(X)\n",
    "\n",
    "X_PCA_sum = np.cumsum(np.round(X_PCA.explained_variance_ratio_, decimals=8)*100) \n",
    "X_PCA_sum_varc = np.array(np.transpose(X_PCA_sum[:,np.newaxis])) \n",
    "\n",
    "X_PCA_sum_varc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과에서 23번까지의 특징을 이용하면 전체 데이터의 80%를 설명할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_y = np.c_[X_PCA_T,Y]\n",
    "# 데이터프레임으로 변경\n",
    "Data = pd.DataFrame(pc_y)\n",
    "\n",
    "X = Data.iloc[:,0:23]\n",
    "Y = Data.iloc[:,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunni\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     79602\n",
      "         1.0       0.83      0.59      0.69       144\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     79746\n",
      "   macro avg       0.92      0.80      0.85     79746\n",
      "weighted avg       1.00      1.00      1.00     79746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.4,random_state=1)\n",
    "\n",
    "Log = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = Log.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79585,    17],\n",
       "       [   59,    85]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 봤을 때 Class = 1인 데이터를 받았을때 1이라고 할 확률이 59%이므로 좋지도 나쁘지도 않은 결과이다\n",
    "\n",
    "=> PCA가 의미 없다는 것을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세번째 분석 방법\n",
    "\n",
    "### 1) 정규화\n",
    "### 2) 로지스틱을 이용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y로 나누고 X값들을 정규화\n",
    "X = data3.iloc[:,1:30]\n",
    "Y = data3.iloc[:,30]\n",
    "for i in X:\n",
    "    X[i] = (X[i] - X[i].mean())/X[i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunni\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     79602\n",
      "           1       0.83      0.59      0.69       144\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     79746\n",
      "   macro avg       0.92      0.80      0.85     79746\n",
      "weighted avg       1.00      1.00      1.00     79746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.4,random_state=1)\n",
    "\n",
    "Log = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = Log.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79585,    17],\n",
       "       [   59,    85]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 봤을 때 Class = 1인 데이터를 받았을때 1이라고 할 확률이 59%이므로 PCA를 이용한 결과와 거의 동일하다고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네번째 분석 방법\n",
    "\n",
    "### 1) 정규화\n",
    "### 2) 분산이 높은 특징 추출(OLS Regression Results)\n",
    "### 3) 로지스틱을 이용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y로 나누고 X값들을 정규화\n",
    "X = data4.iloc[:,1:30]\n",
    "Y = data4.iloc[:,30]\n",
    "for i in X:\n",
    "    X[i] = (X[i] - X[i].mean())/X[i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Class   R-squared:                       0.511\n",
      "Model:                            OLS   Adj. R-squared:                  0.511\n",
      "Method:                 Least Squares   F-statistic:                     7193.\n",
      "Date:                Wed, 12 Jun 2019   Prob (F-statistic):               0.00\n",
      "Time:                        15:57:08   Log-Likelihood:             4.1946e+05\n",
      "No. Observations:              199364   AIC:                        -8.389e+05\n",
      "Df Residuals:                  199334   BIC:                        -8.385e+05\n",
      "Df Model:                          29                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0018   6.61e-05     27.013      0.000       0.002       0.002\n",
      "V1            -0.0037   8.55e-05    -42.981      0.000      -0.004      -0.004\n",
      "V2             0.0048      0.000     33.459      0.000       0.004       0.005\n",
      "V3            -0.0074   8.31e-05    -89.248      0.000      -0.008      -0.007\n",
      "V4             0.0054   7.02e-05     76.405      0.000       0.005       0.005\n",
      "V5            -0.0031      0.000    -26.895      0.000      -0.003      -0.003\n",
      "V6            -0.0022   8.39e-05    -26.291      0.000      -0.002      -0.002\n",
      "V7            -0.0085      0.000    -73.300      0.000      -0.009      -0.008\n",
      "V8             0.0009   7.04e-05     12.764      0.000       0.001       0.001\n",
      "V9            -0.0039    6.7e-05    -58.571      0.000      -0.004      -0.004\n",
      "V10           -0.0087   7.04e-05   -124.123      0.000      -0.009      -0.009\n",
      "V11            0.0063   6.61e-05     95.980      0.000       0.006       0.006\n",
      "V12           -0.0107   6.62e-05   -162.117      0.000      -0.011      -0.011\n",
      "V13           -0.0002   6.61e-05     -3.117      0.002      -0.000   -7.65e-05\n",
      "V14           -0.0126   6.66e-05   -188.628      0.000      -0.013      -0.012\n",
      "V15           -0.0002   6.61e-05     -2.866      0.004      -0.000   -5.99e-05\n",
      "V16           -0.0081   6.61e-05   -121.948      0.000      -0.008      -0.008\n",
      "V17           -0.0134   6.61e-05   -203.197      0.000      -0.014      -0.013\n",
      "V18           -0.0047   6.67e-05    -69.854      0.000      -0.005      -0.005\n",
      "V19            0.0015   6.74e-05     22.232      0.000       0.001       0.002\n",
      "V20            0.0002      0.000      1.706      0.088   -2.65e-05       0.000\n",
      "V21            0.0015   7.07e-05     20.915      0.000       0.001       0.002\n",
      "V22            0.0002   6.78e-05      2.270      0.023     2.1e-05       0.000\n",
      "V23          7.91e-05   7.07e-05      1.119      0.263   -5.94e-05       0.000\n",
      "V24           -0.0003   6.61e-05     -4.954      0.000      -0.000      -0.000\n",
      "V25            0.0003    6.7e-05      3.783      0.000       0.000       0.000\n",
      "V26            0.0002   6.61e-05      3.001      0.003    6.88e-05       0.000\n",
      "V27            0.0006   6.64e-05      9.356      0.000       0.000       0.001\n",
      "V28            0.0004   6.62e-05      5.603      0.000       0.000       0.001\n",
      "Amount         0.0021      0.000      8.575      0.000       0.002       0.003\n",
      "==============================================================================\n",
      "Omnibus:                   412366.463   Durbin-Watson:                   1.961\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       5448815599.062\n",
      "Skew:                          17.078   Prob(JB):                         0.00\n",
      "Kurtosis:                     812.183   Cond. No.                         7.11\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "x2 = sm.add_constant(X)\n",
    "model = sm.OLS(Y,x2)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과에서 각 특징별 t값이 있는데 t값이 높다는 것은 그 특징이 유의미한 특징임을 의미한다.\n",
    "\n",
    "먼저 각 특징별 t값의 절댓값이 50이 넘는 특징을 선택해 분류해 보려고 한다.\n",
    "\n",
    "V3,V4,V7,V9,V10,V11,V12,V14,V16,V17,V18 열한개의 특징을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,[3,4,7,9,10,11,12,14,16,17,18]]\n",
    "Y = data.iloc[:,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunni\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     79602\n",
      "           1       0.84      0.61      0.71       144\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     79746\n",
      "   macro avg       0.92      0.81      0.85     79746\n",
      "weighted avg       1.00      1.00      1.00     79746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.4,random_state=1)\n",
    "\n",
    "Log = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = Log.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79585,    17],\n",
       "       [   56,    88]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여전히 Class = 1인 데이터를 받았을때 1이라고 할 확률이 61%이므로 크게 달라진 점은 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다섯번째 분석 방법\n",
    "\n",
    "### 1) 정규화\n",
    "### 2) 분산이 높은 특징 추출(컴퓨터)\n",
    "### 3) 로지스틱을 이용한 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y로 나누고 X값들을 정규화\n",
    "X = data5.iloc[:,1:30]\n",
    "Y = data5.iloc[:,30]\n",
    "for i in X:\n",
    "    X[i] = (X[i] - X[i].mean())/X[i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.5,random_state=1)\n",
    "Log = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True False False  True False False  True  True  True\n",
      " False  True False  True  True  True False False False False False False\n",
      " False False False False False]\n",
      "[ 3  4  1  1  5  7  1 10  2  1  1  1 13  1 15  1  1  1  9 20  8 19 18 12\n",
      " 17 16 11 14  6]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR \n",
    "from sklearn.feature_selection import RFE \n",
    "from sklearn import datasets\n",
    "selector = RFE(Log, 10).fit(X_train, y_train) #  전체 특징 중 중요한 10개의 특징을 정해줌\n",
    "print(selector.support_) \n",
    "print(selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,[3,4,7,10,11,12,14,16,17,18]]\n",
    "Y = data.iloc[:,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunni\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     79602\n",
      "           1       0.84      0.61      0.71       144\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     79746\n",
      "   macro avg       0.92      0.81      0.85     79746\n",
      "weighted avg       1.00      1.00      1.00     79746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.4,random_state=1)\n",
    "\n",
    "Log = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = Log.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79585,    17],\n",
       "       [   56,    88]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class = 1인 데이터를 받았을때 1이라고 할 확률이 61%이므로 분석 결과 위와 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여섯번째 분석 방법\n",
    "\n",
    "### 1) 정규화\n",
    "### 2) 직관적으로 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = X.iloc[:,30]\n",
    "y_pred = np.zeros((199364,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = X[X.iloc[:,30]==1]\n",
    "B = X[X.iloc[:,30]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_mean = pd.DataFrame(A.mean())\n",
    "A_std = pd.DataFrame(A.std())\n",
    "B_mean = pd.DataFrame(B.mean())\n",
    "B_std = pd.DataFrame(B.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>78200.033708</td>\n",
       "      <td>94806.329851</td>\n",
       "      <td>46673.000303</td>\n",
       "      <td>47449.330060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>-4.632999</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>6.631320</td>\n",
       "      <td>1.933816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>3.489100</td>\n",
       "      <td>-0.005241</td>\n",
       "      <td>4.246547</td>\n",
       "      <td>1.645631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>-6.850015</td>\n",
       "      <td>0.012663</td>\n",
       "      <td>6.982269</td>\n",
       "      <td>1.461915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>4.518063</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>2.805339</td>\n",
       "      <td>1.401313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>-3.087808</td>\n",
       "      <td>0.006131</td>\n",
       "      <td>5.314190</td>\n",
       "      <td>1.362864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>-1.383572</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>1.817774</td>\n",
       "      <td>1.333186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>-5.422761</td>\n",
       "      <td>0.011606</td>\n",
       "      <td>6.985212</td>\n",
       "      <td>1.191909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>0.625195</td>\n",
       "      <td>-0.002245</td>\n",
       "      <td>6.235322</td>\n",
       "      <td>1.167796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>-2.529519</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>2.450965</td>\n",
       "      <td>1.090603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>-5.646788</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>4.861166</td>\n",
       "      <td>1.048837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>3.805626</td>\n",
       "      <td>-0.005415</td>\n",
       "      <td>2.769000</td>\n",
       "      <td>1.003338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>-6.296140</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>4.758574</td>\n",
       "      <td>0.947468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>-0.100056</td>\n",
       "      <td>-0.003023</td>\n",
       "      <td>1.091773</td>\n",
       "      <td>0.995316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>-6.928370</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>4.314998</td>\n",
       "      <td>0.898550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>-0.139255</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>1.059640</td>\n",
       "      <td>0.916471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>-4.145130</td>\n",
       "      <td>0.007950</td>\n",
       "      <td>3.892930</td>\n",
       "      <td>0.844599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>-6.669539</td>\n",
       "      <td>0.012271</td>\n",
       "      <td>7.035489</td>\n",
       "      <td>0.751671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>-2.265586</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>2.914884</td>\n",
       "      <td>0.824858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>0.638346</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>1.521087</td>\n",
       "      <td>0.811743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>0.381991</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>1.259876</td>\n",
       "      <td>0.779093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>0.755212</td>\n",
       "      <td>-0.000944</td>\n",
       "      <td>3.578670</td>\n",
       "      <td>0.722116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>-0.021713</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>1.392154</td>\n",
       "      <td>0.724174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>-0.087463</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>1.691020</td>\n",
       "      <td>0.610299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>-0.114113</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>0.525555</td>\n",
       "      <td>0.605397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>0.064575</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.823966</td>\n",
       "      <td>0.521177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>0.041963</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>0.481518</td>\n",
       "      <td>0.483148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>0.166356</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>1.371467</td>\n",
       "      <td>0.401924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>0.091916</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>0.539651</td>\n",
       "      <td>0.330372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>136.749551</td>\n",
       "      <td>88.367752</td>\n",
       "      <td>286.732453</td>\n",
       "      <td>253.150968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0             0             0             0\n",
       "Time    78200.033708  94806.329851  46673.000303  47449.330060\n",
       "V1         -4.632999      0.004912      6.631320      1.933816\n",
       "V2          3.489100     -0.005241      4.246547      1.645631\n",
       "V3         -6.850015      0.012663      6.982269      1.461915\n",
       "V4          4.518063     -0.004937      2.805339      1.401313\n",
       "V5         -3.087808      0.006131      5.314190      1.362864\n",
       "V6         -1.383572      0.002310      1.817774      1.333186\n",
       "V7         -5.422761      0.011606      6.985212      1.191909\n",
       "V8          0.625195     -0.002245      6.235322      1.167796\n",
       "V9         -2.529519      0.005249      2.450965      1.090603\n",
       "V10        -5.646788      0.008623      4.861166      1.048837\n",
       "V11         3.805626     -0.005415      2.769000      1.003338\n",
       "V12        -6.296140      0.009571      4.758574      0.947468\n",
       "V13        -0.100056     -0.003023      1.091773      0.995316\n",
       "V14        -6.928370      0.011478      4.314998      0.898550\n",
       "V15        -0.139255     -0.000036      1.059640      0.916471\n",
       "V16        -4.145130      0.007950      3.892930      0.844599\n",
       "V17        -6.669539      0.012271      7.035489      0.751671\n",
       "V18        -2.265586      0.004175      2.914884      0.824858\n",
       "V19         0.638346     -0.001477      1.521087      0.811743\n",
       "V20         0.381991     -0.000151      1.259876      0.779093\n",
       "V21         0.755212     -0.000944      3.578670      0.722116\n",
       "V22        -0.021713     -0.000053      1.392154      0.724174\n",
       "V23        -0.087463      0.001891      1.691020      0.610299\n",
       "V24        -0.114113     -0.000082      0.525555      0.605397\n",
       "V25         0.064575      0.001037      0.823966      0.521177\n",
       "V26         0.041963     -0.000157      0.481518      0.483148\n",
       "V27         0.166356      0.000452      1.371467      0.401924\n",
       "V28         0.091916     -0.000230      0.539651      0.330372\n",
       "Amount    136.749551     88.367752    286.732453    253.150968\n",
       "Class       1.000000      0.000000      0.000000      0.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([A_mean,B_mean,A_std,B_std],axis =1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 문제는 Class 값이 1과 0을 구분하는 것이기 때문에 Class = 1과 0을 그룹화 한 뒤 각 특징별 평균,분산의 차이를 확인했는데 V1,V2,V3,V5,V7,V8,V10,V12,V14,V16,V17의 분산이 차이가 있음과 동시에 평균의 차이도 나는 것을 발견했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,[1,2,3,5,7,8,10,12,14,16,17]]\n",
    "Y = data.iloc[:,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunni\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     79602\n",
      "           1       0.90      0.56      0.69       144\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     79746\n",
      "   macro avg       0.95      0.78      0.85     79746\n",
      "weighted avg       1.00      1.00      1.00     79746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.4,random_state=1)\n",
    "\n",
    "Log = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = Log.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 값을 확인했을 때 logistic을 이용하면 한계가 있다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일곱번째 분석 방법\n",
    "### 1) 중요한 특징 추출(세가지 방법)\n",
    "### 2) KNN\n",
    "\n",
    "\n",
    "\n",
    "네번째 분석 할 때 OLS Regression Results에서 t값을 기준으로 특징을 추출\n",
    "\n",
    "위와 같이 50이 넘는 특징을 사용\n",
    "\n",
    "이렇게 V3,V4,V7,V9,V10,V11,V12,V14,V16,V17,V18 열한개의 특징만 사용해 KNN에 모델링을 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 K의 개수\n",
      "3\n",
      "0.7155425219941349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     79602\n",
      "           1       0.62      0.85      0.72       144\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     79746\n",
      "   macro avg       0.81      0.92      0.86     79746\n",
      "weighted avg       1.00      1.00      1.00     79746\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "47.97222222222222\n",
      "\n",
      "\n",
      "\n",
      "현재 K의 개수\n",
      "23\n",
      "0.3668639053254438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     79602\n",
      "           1       0.23      0.86      0.37       144\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     79746\n",
      "   macro avg       0.62      0.93      0.68     79746\n",
      "weighted avg       1.00      0.99      1.00     79746\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "129.31944444444446\n",
      "\n",
      "\n",
      "\n",
      "현재 K의 개수\n",
      "43\n",
      "0.2727272727272727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     79602\n",
      "           1       0.16      0.88      0.27       144\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     79746\n",
      "   macro avg       0.58      0.93      0.63     79746\n",
      "weighted avg       1.00      0.99      0.99     79746\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "158.40972222222223\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,[3,4,7,9,10,11,12,14,16,17,18]]\n",
    "Y = data.iloc[:,30]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.4, random_state=1)\n",
    "\n",
    "for i in range(3,50,20):\n",
    "    reg = KNeighborsRegressor(n_neighbors=i)\n",
    "    \n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    y_pred_classes = np.zeros_like(y_pred)\n",
    "    y_pred_classes[y_pred > 0] = 1 # 이웃중 하나라도 1이 있으면 1로 분류\n",
    "    \n",
    "    print(\"현재 K의 개수\")\n",
    "    print(i)\n",
    "    print(f1_score(y_test, y_pred_classes))\n",
    "    print(classification_report(y_test, y_pred_classes))\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    y_pred_sort = np.sort(y_pred)[::-1] # 예측한 값을 내림차순으로 정렬\n",
    "\n",
    "    a = np.array(pd.DataFrame(y_pred_sort).rank(ascending = False, method = 'min')[0]) # 내림차순한 확률값에 순위매기기(중복 값은 작은 값으로)\n",
    "\n",
    "    rank = np.vstack([y_pred_sort,a]) # 확률값과 순위값 합치기\n",
    "\n",
    "    pd.DataFrame(rank)\n",
    "\n",
    "    cnt = 0\n",
    "    sum_rank = 0\n",
    "    for i in y_test:\n",
    "        if i==1: # 클래스가 1인 데이터의 확률값과 순위를 확인해 sum_rank에 더해줌\n",
    "            sum_rank += np.where(rank[0] == y_pred[cnt])[0][0]\n",
    "        cnt += 1\n",
    "\n",
    "    print(sum_rank / sum(y_test)) # 전체 순위의 평균값 출력\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다섯번째 분석 할 때 selector.ranking_에서 특징 10개씩 묶었을 때 가장 R-Square값이 높은 10개의 특징을 추출\n",
    "\n",
    "이렇게 10개의 특징만 사용해 KNN에 모델링을 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 K의 개수\n",
      "3\n",
      "0.7155425219941349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     79602\n",
      "           1       0.62      0.85      0.72       144\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     79746\n",
      "   macro avg       0.81      0.92      0.86     79746\n",
      "weighted avg       1.00      1.00      1.00     79746\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "47.74305555555556\n",
      "\n",
      "\n",
      "\n",
      "현재 K의 개수\n",
      "23\n",
      "0.362844702467344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     79602\n",
      "           1       0.23      0.87      0.36       144\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     79746\n",
      "   macro avg       0.61      0.93      0.68     79746\n",
      "weighted avg       1.00      0.99      1.00     79746\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "128.44444444444446\n",
      "\n",
      "\n",
      "\n",
      "현재 K의 개수\n",
      "43\n",
      "0.2677824267782427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     79602\n",
      "           1       0.16      0.89      0.27       144\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     79746\n",
      "   macro avg       0.58      0.94      0.63     79746\n",
      "weighted avg       1.00      0.99      0.99     79746\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "153.58333333333334\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,[3,4,7,10,11,12,14,16,17,18]]\n",
    "Y = data.iloc[:,30]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.4, random_state=1)\n",
    "\n",
    "for i in range(3,50,20):\n",
    "    reg = KNeighborsRegressor(n_neighbors=i)\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    y_pred_classes = np.zeros_like(y_pred)\n",
    "    y_pred_classes[y_pred > 0] = 1 \n",
    "    \n",
    "    print(\"현재 K의 개수\")\n",
    "    print(i)\n",
    "    print(f1_score(y_test, y_pred_classes))\n",
    "    print(classification_report(y_test, y_pred_classes))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    y_pred_sort = np.sort(y_pred)[::-1] # 예측한 값을 내림차순으로 정렬\n",
    "\n",
    "    a = np.array(pd.DataFrame(y_pred_sort).rank(ascending = False, method = 'min')[0]) # 내림차순한 확률값에 순위매기기(중복 값은 작은 값으로)\n",
    "\n",
    "    rank = np.vstack([y_pred_sort,a]) # 확률값과 순위값 합치기\n",
    "\n",
    "    pd.DataFrame(rank)\n",
    "\n",
    "    cnt = 0\n",
    "    sum_rank = 0\n",
    "    for i in y_test:\n",
    "        if i==1: # 클래스가 1인 데이터의 확률값과 순위를 확인해 sum_rank에 더해줌\n",
    "            sum_rank += np.where(rank[0] == y_pred[cnt])[0][0]\n",
    "        cnt += 1\n",
    "\n",
    "    print(sum_rank / sum(y_test)) # 전체 순위의 평균값 출력\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여섯번째 분석 할 때 직접 클래스별 특징의 평균과 분산을 비교해 가장 육안으로 차이가 나는 특징 11개를 추출\n",
    "이렇게 V1,V2,V3,V5,V7,V8,V10,V12,V14,V16,V17 열한개의 특징만 사용해 KNN에 모델링을 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 K의 개수\n",
      "3\n",
      "0.7407407407407408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     79602\n",
      "           1       0.67      0.83      0.74       144\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     79746\n",
      "   macro avg       0.83      0.92      0.87     79746\n",
      "weighted avg       1.00      1.00      1.00     79746\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "48.708333333333336\n",
      "\n",
      "\n",
      "\n",
      "현재 K의 개수\n",
      "23\n",
      "0.39360000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     79602\n",
      "           1       0.26      0.85      0.39       144\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     79746\n",
      "   macro avg       0.63      0.92      0.70     79746\n",
      "weighted avg       1.00      1.00      1.00     79746\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "125.11805555555556\n",
      "\n",
      "\n",
      "\n",
      "현재 K의 개수\n",
      "43\n",
      "0.27114967462039047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     79602\n",
      "           1       0.16      0.87      0.27       144\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     79746\n",
      "   macro avg       0.58      0.93      0.63     79746\n",
      "weighted avg       1.00      0.99      0.99     79746\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "160.97916666666666\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,[1,2,3,5,7,8,10,12,14,16,17]]\n",
    "Y = data.iloc[:,30]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.4, random_state=1)\n",
    "\n",
    "for i in range(3,50,20):\n",
    "    reg = KNeighborsRegressor(n_neighbors=i)\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    y_pred_classes = np.zeros_like(y_pred)\n",
    "    y_pred_classes[y_pred > 0] = 1 \n",
    "    \n",
    "    print(\"현재 K의 개수\")\n",
    "    print(i)\n",
    "    print(f1_score(y_test, y_pred_classes))\n",
    "    print(classification_report(y_test, y_pred_classes))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    y_pred_sort = np.sort(y_pred)[::-1] # 예측한 값을 내림차순으로 정렬\n",
    "\n",
    "    a = np.array(pd.DataFrame(y_pred_sort).rank(ascending = False, method = 'min')[0]) # 내림차순한 확률값에 순위매기기(중복 값은 작은 값으로)\n",
    "\n",
    "    rank = np.vstack([y_pred_sort,a]) # 확률값과 순위값 합치기\n",
    "\n",
    "    pd.DataFrame(rank)\n",
    "\n",
    "    cnt = 0\n",
    "    sum_rank = 0\n",
    "    for i in y_test:\n",
    "        if i==1: # 클래스가 1인 데이터의 확률값과 순위를 확인해 sum_rank에 더해줌\n",
    "            sum_rank += np.where(rank[0] == y_pred[cnt])[0][0]\n",
    "        cnt += 1\n",
    "\n",
    "    print(sum_rank / sum(y_test)) # 전체 순위의 평균값 출력\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세개의 KNN분석을 봤는데 결과적으로 랭킹의 평균이 가장 낮게 하기 위해서는 컴퓨터가 중요하다고 생각하는 10개의 특징으로 모델링을 했을 때 가장 낮게 나온것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 모델에서 X의 값을 정규화 한 뒤 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     79602\n",
      "           1       0.60      0.85      0.70       144\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     79746\n",
      "   macro avg       0.80      0.92      0.85     79746\n",
      "weighted avg       1.00      1.00      1.00     79746\n",
      "\n",
      "\n",
      "\n",
      "1인 데이터들의 평균 순위 \n",
      "50.09027777777778\n"
     ]
    }
   ],
   "source": [
    "# X, Y로 나누고 X값들을 정규화\n",
    "X = data.iloc[:,1:30]\n",
    "Y = data.iloc[:,30]\n",
    "for i in X:\n",
    "    X[i] = (X[i] - X[i].mean())/X[i].std()\n",
    "\n",
    "X = X.iloc[:,[2,3,6,8,9,10,11,13,15,16,17]] # V3,V4,V7,V10,V11,V12,V14,V16,V17,V18 열개의 특징사용\n",
    "Y = data.iloc[:,30]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.4, random_state=1)\n",
    "\n",
    "reg = KNeighborsRegressor(n_neighbors=3) # 이웃의 수를 3개 확인\n",
    "    \n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "y_pred_classes = np.zeros_like(y_pred)\n",
    "y_pred_classes[y_pred > 0] = 1 # 이웃중 하나라도 1이 있으면 1로 분류\n",
    "    \n",
    "\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "print()\n",
    "print()\n",
    "    \n",
    "y_pred_sort = np.sort(y_pred)[::-1] # 예측한 값을 내림차순으로 정렬\n",
    "\n",
    "a = np.array(pd.DataFrame(y_pred_sort).rank(ascending = False, method = 'min')[0]) # 내림차순한 확률값에 순위매기기(중복 값은 작은 값으로)\n",
    "\n",
    "rank = np.vstack([y_pred_sort,a]) # 확률값과 순위값 합치기\n",
    "\n",
    "pd.DataFrame(rank)\n",
    "\n",
    "cnt = 0\n",
    "sum_rank = 0\n",
    "for i in y_test:\n",
    "    if i==1: # 클래스가 1인 데이터의 확률값과 순위를 확인해 sum_rank에 더해줌\n",
    "        sum_rank += np.where(rank[0] == y_pred[cnt])[0][0]\n",
    "    cnt += 1\n",
    "\n",
    "print(\"1인 데이터들의 평균 순위 \")\n",
    "print(sum_rank / sum(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화를 했을 떄 랭킹의 평균 순위가 높아지는것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - 최종 모델은 다음과 같다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각 랭킹값의 평균이 최소가 되는 분류모델은 컴퓨터가 중요하다고 생각하는 10개의 특징(V3,V4,V7,V10,V11,V12,V14,V16,V17,V18)으로 KNN 모델링 했을 때 가장 최소가 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 K의 개수\n",
      "1\n",
      "0.7155425219941349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     79602\n",
      "           1       0.62      0.85      0.72       144\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     79746\n",
      "   macro avg       0.81      0.92      0.86     79746\n",
      "weighted avg       1.00      1.00      1.00     79746\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "99\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "99\n",
      "0\n",
      "0\n",
      "197\n",
      "0\n",
      "197\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "99\n",
      "0\n",
      "197\n",
      "99\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "99\n",
      "0\n",
      "0\n",
      "197\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "197\n",
      "0\n",
      "99\n",
      "0\n",
      "0\n",
      "99\n",
      "0\n",
      "197\n",
      "197\n",
      "197\n",
      "99\n",
      "0\n",
      "0\n",
      "0\n",
      "99\n",
      "0\n",
      "99\n",
      "0\n",
      "0\n",
      "132\n",
      "0\n",
      "99\n",
      "0\n",
      "197\n",
      "0\n",
      "99\n",
      "197\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "197\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "132\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "132\n",
      "197\n",
      "197\n",
      "99\n",
      "197\n",
      "99\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "197\n",
      "197\n",
      "99\n",
      "197\n",
      "132\n",
      "197\n",
      "99\n",
      "0\n",
      "0\n",
      "0\n",
      "99\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "99\n",
      "197\n",
      "0\n",
      "197\n",
      "197\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "132\n",
      "197\n",
      "99\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "47.74305555555556\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,[3,4,7,10,11,12,14,16,17,18]]\n",
    "Y = data.iloc[:,30]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.4, random_state=1)\n",
    "\n",
    "reg = KNeighborsRegressor(n_neighbors=3) # 이웃의 수를 3부터 293까지 확인\n",
    "    \n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "y_pred_classes = np.zeros_like(y_pred)\n",
    "y_pred_classes[y_pred > 0] = 1 # 이웃중 하나라도 1이 있으면 1로 분류\n",
    "    \n",
    "print(\"현재 K의 개수\")\n",
    "print(i)\n",
    "print(f1_score(y_test, y_pred_classes))\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "    \n",
    "y_pred_sort = np.sort(y_pred)[::-1] # 예측한 값을 내림차순으로 정렬\n",
    "\n",
    "a = np.array(pd.DataFrame(y_pred_sort).rank(ascending = False, method = 'min')[0]) # 내림차순한 확률값에 순위매기기(중복 값은 작은 값으로)\n",
    "\n",
    "rank = np.vstack([y_pred_sort,a]) # 확률값과 순위값 합치기\n",
    "\n",
    "pd.DataFrame(rank)\n",
    "\n",
    "cnt = 0\n",
    "sum_rank = 0\n",
    "for i in y_test:\n",
    "    if i==1: # 클래스가 1인 데이터의 확률값과 순위를 확인해 sum_rank에 더해줌\n",
    "        sum_rank += np.where(rank[0] == y_pred[cnt])[0][0]\n",
    "        print(np.where(rank[0] == y_pred[cnt])[0][0])\n",
    "    cnt += 1\n",
    "\n",
    "print(sum_rank / sum(y_test)) # 전체 순위의 평균값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79527,    75],\n",
       "       [   22,   122]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred_classes)\n",
    "cnf_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
